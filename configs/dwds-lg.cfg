[system]
gpu_allocator = null
seed = 0

[nlp]
lang = "de"
pipeline = ["tok2vec","tagger","morphologizer","parser","lemmatizer", "tok2vec_ner", "ner"]
disabled = []
before_creation = null
after_creation = null
after_pipeline_creation = null
batch_size = 64
tokenizer = {"@tokenizers":"spacy.Tokenizer.v1"}

[components]

[components.tok2vec]
source = "training/dep-lg/model-best"

[components.lemmatizer]
source = "training/dep-lg/model-best"

[components.morphologizer]
source = "training/dep-lg/model-best"

[components.parser]
source = "training/dep-lg/model-best"

[components.tagger]
source = "training/dep-lg/model-best"

[components.tok2vec_ner]
source = "training/ner-lg/model-best"

[components.ner]
source = "training/ner-lg/model-best"

[initialize]
vectors = "de_core_news_lg"
